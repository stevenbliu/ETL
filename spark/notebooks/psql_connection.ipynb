{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import utils as utils\n",
    "#.master(\"spark://spark-master:7077\") \\\n",
    "\n",
    "problem_data_path = 'problematic_transactions.csv'\n",
    "\n",
    "utils.verify_path(problem_data_path)\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+--------+-------------------+\n",
      "|transaction_id|user_id|amount|    type|          timestamp|\n",
      "+--------------+-------+------+--------+-------------------+\n",
      "|    1704169733|      9|361.83|transfer|2024-01-01 20:28:53|\n",
      "|    1706848193|     77| 55.28|transfer|2024-02-01 20:29:53|\n",
      "|    1709353853|     69| 82.96|purchase|2024-03-01 20:30:53|\n",
      "|    1712028713|     88| 36.10|transfer|2024-04-01 20:31:53|\n",
      "|    1714620773|     22| 94.44|transfer|2024-05-01 20:32:53|\n",
      "|    1717299233|     73|408.42|purchase|2024-06-01 20:33:53|\n",
      "|    1719891293|     64|954.82|transfer|2024-07-01 20:34:53|\n",
      "|    1722569753|     59|410.94|purchase|2024-08-01 20:35:53|\n",
      "|    1725248213|     16|797.11|purchase|2024-09-01 20:36:53|\n",
      "|    1727840273|     42|802.94|purchase|2024-10-01 20:37:53|\n",
      "|    1730518733|     43| 35.93|transfer|2024-11-01 20:38:53|\n",
      "|    1733114393|     69|555.90|  refund|2024-12-01 20:39:53|\n",
      "|    1704170453|     55| 15.16|transfer|2024-01-01 20:40:53|\n",
      "|    1706848913|     24|489.46|transfer|2024-02-01 20:41:53|\n",
      "|    1709354573|      6| 87.45|  refund|2024-03-01 20:42:53|\n",
      "|    1712029433|      2|646.71|purchase|2024-04-01 20:43:53|\n",
      "|    1714621493|     27|424.29|transfer|2024-05-01 20:44:53|\n",
      "|    1717299953|     56|858.77|  refund|2024-06-01 20:45:53|\n",
      "|    1719892013|     80| 24.86|purchase|2024-07-01 20:46:53|\n",
      "|    1722570473|      3|217.34|  refund|2024-08-01 20:47:53|\n",
      "+--------------+-------+------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "Path exists!\n",
      "+--------------+-------+--------------+--------+--------------------+\n",
      "|transaction_id|user_id|        amount|    type|           timestamp|\n",
      "+--------------+-------+--------------+--------+--------------------+\n",
      "|    1704314682|     45|960.52 dollars|  refund|2024-01-03T12:44:42Z|\n",
      "|    1706993142|     70|434.41 dollars|purchase|2024-02-03T12:45:42Z|\n",
      "|    1709498802|     80|856.68 dollars|  refund|2024-03-03T12:46:42Z|\n",
      "|    1712173662|     10|          NULL|transfer|2024-04-03T12:47:42Z|\n",
      "|    1714765722|     88|        108.19|transfer|2024-05-03T12:44:42Z|\n",
      "|    1717444182|     45|          NULL|  refund|2024-06-03T12:49:42Z|\n",
      "|    1720036242|     24|        950.52|purchase|2024-07-03T12:50:42Z|\n",
      "|    1720036242|     24|        950.52|purchase|2024-07-03T12:50:42Z|\n",
      "|    1722714702|     51|        479.82|transfer|2024/08-03T12:51:42Z|\n",
      "|    1725393162|     93|        671.08|  refund|2024-09-03T11:39:42Z|\n",
      "|    1727985222|     60|505.53 dollars|purchase|2024-10-03T12:53:42Z|\n",
      "|    1730667282|     18|145.33 dollars|  refund|2024-11-03T12:54:42Z|\n",
      "|    1733259342|     71|        575.49|transfer|2024-12-03T11:27:42Z|\n",
      "|    1704315402|     44|        954.79|purchase|2024-01-03T12:18:42Z|\n",
      "|    1706993862|     37|          NULL|transfer|2024-02-03T12:57:42Z|\n",
      "|    1709499522|     44|         388.2|purchase|2024-03-03T12:58:42Z|\n",
      "|    1709499522|     44|         388.2|purchase|2024-03-03T12:58:42Z|\n",
      "|    1712174382|     97|        715.28|purchase|2024-04-03T12:59:42Z|\n",
      "|    1712174382|     97|        919.29|purchase|2024-04-03T12:59:42Z|\n",
      "|    1714766442|     65|          NULL|transfer|2024-05-03T13:00:42Z|\n",
      "+--------------+-------+--------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def get_spark_session(app_name=\"SparkApplication\", master=\"local[*]\", config_options=None):\n",
    "    \"\"\"\n",
    "    Creates and returns a SparkSession with specified configurations.\n",
    "    :param app_name: Name of the Spark application\n",
    "    :param master: Spark master URL\n",
    "    :param config_options: Additional configurations as a dictionary\n",
    "    :return: SparkSession instance\n",
    "    \"\"\"\n",
    "    builder = SparkSession.builder.appName(app_name).master(master)\n",
    "    \n",
    "    if config_options:\n",
    "        for key, value in config_options.items():\n",
    "            builder = builder.config(key, value)\n",
    "    \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "def get_jdbc_connection_properties(user, password, driver=\"org.postgresql.Driver\"):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of JDBC connection properties.\n",
    "    :param user: Database username\n",
    "    :param password: Database password\n",
    "    :param driver: JDBC driver class\n",
    "    :return: Dictionary of connection properties\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"user\": user,\n",
    "        \"password\": password,\n",
    "        \"driver\": driver\n",
    "    }\n",
    "\n",
    "def get_psql_data(jdbc_url, table_name, user, password, jdbc_jar_path=\"/opt/spark/jars/postgresql-42.7.4.jar\"):\n",
    "    \"\"\"\n",
    "    Loads data from a PostgreSQL table into a Spark DataFrame.\n",
    "    :param jdbc_url: JDBC URL for the PostgreSQL database\n",
    "    :param table_name: Table name to load\n",
    "    :param user: Database username\n",
    "    :param password: Database password\n",
    "    :param jdbc_jar_path: Path to the PostgreSQL JDBC driver jar\n",
    "    :return: Spark DataFrame\n",
    "    \"\"\"\n",
    "    spark = get_spark_session(\n",
    "        app_name=\"Spark with PostgreSQL\",\n",
    "        config_options={\"spark.jars\": jdbc_jar_path}\n",
    "    )\n",
    "    \n",
    "    connection_properties = get_jdbc_connection_properties(user, password)\n",
    "    \n",
    "    df = spark.read.jdbc(url=jdbc_url, table=table_name, properties=connection_properties)\n",
    "    return df\n",
    "\n",
    "import utils  # Assuming this contains the verify_path function\n",
    "\n",
    "def get_csv_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file into a Spark DataFrame.\n",
    "    :param file_path: Path to the CSV file\n",
    "    :return: Spark DataFrame\n",
    "    \"\"\"\n",
    "    spark = get_spark_session(app_name=\"CSVDataLoader\")\n",
    "    \n",
    "    # Verify the file path exists\n",
    "    utils.verify_path(file_path)\n",
    "    \n",
    "    # Read the CSV file into a Spark DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    return df\n",
    "    \n",
    "jdbc_url = \"jdbc:postgresql://psql-postgres-1:5432/mydatabase\"\n",
    "table_name = \"transactions\"\n",
    "user = \"myuser\"\n",
    "password = \"mysecretpassword\"\n",
    "\n",
    "psql_df = get_psql_data(jdbc_url, table_name, user, password)\n",
    "print(psql_df.show())\n",
    "\n",
    "csv_file_path = 'problematic_transactions.csv'\n",
    "\n",
    "csv_df = get_csv_data(csv_file_path)\n",
    "print(csv_df.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_psql_data():\n",
    "    jdbc_path = \"/opt/spark/jars/postgresql-42.7.4.jar\"\n",
    "    \n",
    "    # Initialize Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Spark with PostgreSQL\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.jars\", jdbc_path) \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # JDBC connection properties\n",
    "    jdbc_url = \"jdbc:postgresql://psql-postgres-1:5432/mydatabase\"\n",
    "    connection_properties = {\n",
    "        \"user\": \"myuser\",\n",
    "        \"password\": \"mysecretpassword\",\n",
    "        \"driver\": \"org.postgresql.Driver\"\n",
    "    }\n",
    "    \n",
    "    # Load a table into Spark\n",
    "    df = spark.read.jdbc(url=jdbc_url, table=\"transactions\", properties=connection_properties)\n",
    "    return df.show()\n",
    "\n",
    "\n",
    "df = get_psql_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists!\n",
      "+--------------+-------+--------------+--------+--------------------+\n",
      "|transaction_id|user_id|        amount|    type|           timestamp|\n",
      "+--------------+-------+--------------+--------+--------------------+\n",
      "|    1704314682|     45|960.52 dollars|  refund|2024-01-03T12:44:42Z|\n",
      "|    1706993142|     70|434.41 dollars|purchase|2024-02-03T12:45:42Z|\n",
      "|    1709498802|     80|856.68 dollars|  refund|2024-03-03T12:46:42Z|\n",
      "|    1712173662|     10|          NULL|transfer|2024-04-03T12:47:42Z|\n",
      "|    1714765722|     88|        108.19|transfer|2024-05-03T12:44:42Z|\n",
      "|    1717444182|     45|          NULL|  refund|2024-06-03T12:49:42Z|\n",
      "|    1720036242|     24|        950.52|purchase|2024-07-03T12:50:42Z|\n",
      "|    1720036242|     24|        950.52|purchase|2024-07-03T12:50:42Z|\n",
      "|    1722714702|     51|        479.82|transfer|2024/08-03T12:51:42Z|\n",
      "|    1725393162|     93|        671.08|  refund|2024-09-03T11:39:42Z|\n",
      "|    1727985222|     60|505.53 dollars|purchase|2024-10-03T12:53:42Z|\n",
      "|    1730667282|     18|145.33 dollars|  refund|2024-11-03T12:54:42Z|\n",
      "|    1733259342|     71|        575.49|transfer|2024-12-03T11:27:42Z|\n",
      "|    1704315402|     44|        954.79|purchase|2024-01-03T12:18:42Z|\n",
      "|    1706993862|     37|          NULL|transfer|2024-02-03T12:57:42Z|\n",
      "|    1709499522|     44|         388.2|purchase|2024-03-03T12:58:42Z|\n",
      "|    1709499522|     44|         388.2|purchase|2024-03-03T12:58:42Z|\n",
      "|    1712174382|     97|        715.28|purchase|2024-04-03T12:59:42Z|\n",
      "|    1712174382|     97|        919.29|purchase|2024-04-03T12:59:42Z|\n",
      "|    1714766442|     65|          NULL|transfer|2024-05-03T13:00:42Z|\n",
      "+--------------+-------+--------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- transaction_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "+--------------+--------------+\n",
      "|transaction_id|        amount|\n",
      "+--------------+--------------+\n",
      "|    1704314682|960.52 dollars|\n",
      "|    1706993142|434.41 dollars|\n",
      "|    1709498802|856.68 dollars|\n",
      "|    1712173662|          NULL|\n",
      "|    1714765722|        108.19|\n",
      "|    1717444182|          NULL|\n",
      "|    1720036242|        950.52|\n",
      "|    1720036242|        950.52|\n",
      "|    1722714702|        479.82|\n",
      "|    1725393162|        671.08|\n",
      "|    1727985222|505.53 dollars|\n",
      "|    1730667282|145.33 dollars|\n",
      "|    1733259342|        575.49|\n",
      "|    1704315402|        954.79|\n",
      "|    1706993862|          NULL|\n",
      "|    1709499522|         388.2|\n",
      "|    1709499522|         388.2|\n",
      "|    1712174382|        715.28|\n",
      "|    1712174382|        919.29|\n",
      "|    1714766442|          NULL|\n",
      "+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_csv_data():\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    # Initialize SparkSession\n",
    "    spark = SparkSession.builder\\\n",
    "    .appName(\"CSVDataLoader\")\\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "    # Define the file path\n",
    "    problem_data_path = 'problematic_transactions.csv'\n",
    "\n",
    "    # Verify the file path exists (assuming `utils.verify_path` is a custom function)\n",
    "    utils.verify_path(problem_data_path)\n",
    "\n",
    "    # Read the CSV file into a Spark DataFrame\n",
    "    df = spark.read.csv(problem_data_path, header=True, inferSchema=True)\n",
    "\n",
    "    # Show a sample of the data (optional)\n",
    "    df.show()\n",
    "\n",
    "    # Return the Spark DataFrame\n",
    "    return df\n",
    "# Load CSV data using Spark\n",
    "csv_df = get_csv_data()\n",
    "\n",
    "# Perform Spark transformations\n",
    "csv_df.printSchema()  # Show the schema of the DataFrame\n",
    "csv_df.select(\"transaction_id\", \"amount\").show()  # Select specific columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+--------+-------------------+\n",
      "|transaction_id|user_id|amount|    type|          timestamp|\n",
      "+--------------+-------+------+--------+-------------------+\n",
      "|    1704169733|      9|361.83|transfer|2024-01-01 20:28:53|\n",
      "|    1706848193|     77| 55.28|transfer|2024-02-01 20:29:53|\n",
      "|    1709353853|     69| 82.96|purchase|2024-03-01 20:30:53|\n",
      "|    1712028713|     88| 36.10|transfer|2024-04-01 20:31:53|\n",
      "|    1714620773|     22| 94.44|transfer|2024-05-01 20:32:53|\n",
      "|    1717299233|     73|408.42|purchase|2024-06-01 20:33:53|\n",
      "|    1719891293|     64|954.82|transfer|2024-07-01 20:34:53|\n",
      "|    1722569753|     59|410.94|purchase|2024-08-01 20:35:53|\n",
      "|    1725248213|     16|797.11|purchase|2024-09-01 20:36:53|\n",
      "|    1727840273|     42|802.94|purchase|2024-10-01 20:37:53|\n",
      "|    1730518733|     43| 35.93|transfer|2024-11-01 20:38:53|\n",
      "|    1733114393|     69|555.90|  refund|2024-12-01 20:39:53|\n",
      "|    1704170453|     55| 15.16|transfer|2024-01-01 20:40:53|\n",
      "|    1706848913|     24|489.46|transfer|2024-02-01 20:41:53|\n",
      "|    1709354573|      6| 87.45|  refund|2024-03-01 20:42:53|\n",
      "|    1712029433|      2|646.71|purchase|2024-04-01 20:43:53|\n",
      "|    1714621493|     27|424.29|transfer|2024-05-01 20:44:53|\n",
      "|    1717299953|     56|858.77|  refund|2024-06-01 20:45:53|\n",
      "|    1719892013|     80| 24.86|purchase|2024-07-01 20:46:53|\n",
      "|    1722570473|      3|217.34|  refund|2024-08-01 20:47:53|\n",
      "+--------------+-------+------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "(1704169733, 9, Decimal('361.83'), 'transfer', datetime.datetime(2024, 1, 1, 20, 28, 53))\n",
      "(1706848193, 77, Decimal('55.28'), 'transfer', datetime.datetime(2024, 2, 1, 20, 29, 53))\n",
      "(1709353853, 69, Decimal('82.96'), 'purchase', datetime.datetime(2024, 3, 1, 20, 30, 53))\n",
      "(1712028713, 88, Decimal('36.10'), 'transfer', datetime.datetime(2024, 4, 1, 20, 31, 53))\n",
      "(1714620773, 22, Decimal('94.44'), 'transfer', datetime.datetime(2024, 5, 1, 20, 32, 53))\n",
      "(1717299233, 73, Decimal('408.42'), 'purchase', datetime.datetime(2024, 6, 1, 20, 33, 53))\n",
      "(1719891293, 64, Decimal('954.82'), 'transfer', datetime.datetime(2024, 7, 1, 20, 34, 53))\n",
      "(1722569753, 59, Decimal('410.94'), 'purchase', datetime.datetime(2024, 8, 1, 20, 35, 53))\n",
      "(1725248213, 16, Decimal('797.11'), 'purchase', datetime.datetime(2024, 9, 1, 20, 36, 53))\n",
      "(1727840273, 42, Decimal('802.94'), 'purchase', datetime.datetime(2024, 10, 1, 20, 37, 53))\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=\"psql-postgres-1\",\n",
    "    port=5432,\n",
    "    user=\"myuser\",\n",
    "    password=\"mysecretpassword\",\n",
    "    dbname=\"mydatabase\"\n",
    ")\n",
    "print(\"Connection successful!\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT * FROM transactions;\n",
    "\"\"\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Print each row\n",
    "for i, row in enumerate(rows):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(row)\n",
    "    \n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|Alice| 29|\n",
      "|  Bob| 35|\n",
      "|Cathy| 45|\n",
      "+-----+---+\n",
      "\n",
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|  Bob| 35|\n",
      "|Cathy| 45|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "if 'spark' in globals():\n",
    "    spark.stop()\n",
    "    \n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Test\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create a simple DataFrame\n",
    "data = [(\"Alice\", 29), (\"Bob\", 35), (\"Cathy\", 45)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Perform a simple transformation: filter by age > 30\n",
    "df_filtered = df.filter(df[\"Age\"] > 30)\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "df_filtered.show()\n",
    "\n",
    "# Stop the Spark session when done\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spark' in globals():\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyspark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpyspark\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pyspark' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|  Alice|  1|\n",
      "|    Bob|  2|\n",
      "|Charlie|  3|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SimpleApp\").getOrCreate()\n",
    "\n",
    "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
